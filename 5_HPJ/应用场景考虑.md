# Evaluation

## 导入导出部分

### 导入

需要导入的数据：  

1. 原始问答
2. 基于某个原始问题，单独或者批量导入标准问题
3. 对于已有的标准问题，导入候选答案
4. 评估结果  
5. 评估结果分析  

### 导出

需要导出的数据：  

1. 原始问题  
    需要用于创建标准问题  
2. 标准问题  
    需要用于创建候选回答
3. 评估结果  
    评估结果需要用来进行分析，然后给结果打分  
    用来评估LLM对问题的解决能力  

## 查询部分

1. 原始问题
    1. 原始问题ID  
    2. 原始答案ID  
    3. 状态（已处理、未处理、已忽略）  
    4. 标准问题ID  
    5. 详情  
2. 原始回答
3. 标准问题
4. 候选回答
5. 标准回答  
6. 评估结果  
7. 评估结果分析  

以上可能需要实现的功能：  

1. 分页查询  
2. 排序查询  
3. 筛选查询  

## 修改部分

1. 是否要支持对单个标准问题添加标准答案？  
2. 数据集版本更新：添加and修改and删除问题？  
    或许还是将版本标为多值属性？  
    添加、修改都作为新问题，删除就不再将问题标注新版本  

## 用例场景

### 原始数据导入

1. 导入原始问答以及标准化

    ```mermaid
    flowchart TD
        A[原始问答数据] -->|后端处理| B[导入原始问题及回答]
        B --> |导出问题|C[标准化问题]
        C --> |导入| D[收纳标准问题]
    ```

    注意点：  
    1. 标准问题可以分两大类  
        1. 主观题  
            maybe 多个踩分点  
        2. 客观题  
            此处作何考虑呢，因为主观题的判定比较难，考察维度高，因此考虑和客观题分表，但是客观题不同题型怎么说，要不要分表？  
            1. 选择（全部单选）  
            2. 正误  
    2. 所有标准问题来源于原始问题  
        可以溯源至原始问题（也就是通过id联系吧）  

    问题：  
    1. 标准问题id是要递增的，那么是两个表一起增还是各自增？  
        1. 方法1：两个表一起增  
        2. 方法2：各自增  

2. 候选答案导入，及选入标准答案  

    ```mermaid
    flowchart TD
        A[获取标准问题] --> |总之某种方式| B[得到候选回答]
        B --> |导入| C[候选回答]
        C --> |人工判断| D{是否合适}
        D --> |是| E[选入标准答案]
        D --> |否| F[标注为否决]
    ```

    注意点：  
    1. 候选回答的获取方式此处不多探究，总之默认能获取到候选回答  
    2. 候选回答是根据标准问题获取的，因此其必须与某一个标准问题相关联  
    3. 候选回答目前选择人工判断是否合适，考虑在前端给出此功能  

    问题：  
    1. 因为标准问题是考虑分表的，那么候选回答怎么办？  
        1. 方法1：也分表
        2. 方法2：标注问题类型  
    2. 候选答案怎么进入标准答案表?  

### 数据检查

1. 原始问答对检查  
    1. 基础部分：  
        1. 展示原始问答对  
        2. 展示其他一些信息  
    2. 考虑拓展部分：  
        1. 显示是否有相关标准问题  

2. 标准问题检查
    1. 基础部分：  
        1. 展示标准问题基础信息  
        2. 展示其他一些信息
        3. 展示tags
        4. 展示标准回答状态（有/无）  
        5. 版本信息  
            考虑一个问题可以存在于多个版本  
    2. 考虑拓展部份：
        1. 可以显示是否有未处理的候选回答  
        2. 可以显示相关标准回答的具体信息  
        3. 考虑问题质量相关评估信息  
    3. 存疑部分：  
        1. 要不要考虑删除标准问题？  

3. 标准回答检查
    1. 基础部分：  
        1. 展示标准回答基础信息
        2. 展示其他一些信息
        3. 所属标准问题id
        4. 关联候选回答id
    2. 存疑部分：
        1. 是否要维护标准回答的版本信息？  
            感觉没必要，或许考虑实现删除和修改标准回答就行了？  
        2. 是否要考虑标准回答的质量评估？  

### 评估相关模块

1. 标准问题评估：  

    ```mermaid
    flowchart TD
        A[筛选问题] --> |导出| B[标准问题]
        B --> |总之通过某种方法进行了评估| C[评估结果]
        D[添加新评估结果标签]
        C --> |添加标签| E[评估结果导入]
        D --> E
    ```

    注意点：  
    1. 此处筛选问题首先就要选有标准回答的问题  
    2. 总之标签考虑通过人工创建  
    3. 评估结果必须和某一个标准问题关联  
    4. 评估结果也只能和一个标签关联  

2. 评估结果分析：  

    ```mermaid
    A[评估结果] --> |关联| B[相关问题的标准回答]
    B --> |导出分析| C[评估结果分析]
    C --> |分析结果| D[评估结果分析导入]
    ```

    问题：  
    此处考虑使用大模型分析？  
    那么可能也有多次分析结果？  
